{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_as_geometry_src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Notebook: Data as geometry\n",
    "*Introduction to intelligent systems - the toolbox* \n",
    "\n",
    "** Objectives **: The objectives of this notebook is to understand (i) ..., (ii) ... and (iii) ...\n",
    "\n",
    "***\n",
    "\n",
    "## Introduction\n",
    "We will in this notebook investigate how the following simple neural network works:\n",
    "\n",
    "<img src=\"src/figures/network.PNG\",width=500,height=500>\n",
    "\n",
    "The network is called a feed forward network, because information is only flowing from left to right. The network has two input neurons, three neurons in the hidden layer and a single output unit. \n",
    "\n",
    "## Data\n",
    "We will adjust our network such that it can distingues between two classes of 2D points, a inner class of red points and outer ring of blue points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets generate 500 points from two classes\n",
    "N = 500\n",
    "X, Y = generate_circle_data(N)\n",
    "plot_data(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "* Can you explain how the 2D points were generated?\n",
    "* Adjust the weights below such that the 3 lines alltogether divide the region of the red points from the region of the blue points (as good as possible). Hint: (1) what is the connection between the weights and the black 3 arrows in the plot? (2) what is the connection between the lines and the black arrows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = widget1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell each time you update a value in the above widget\n",
    "W = np.array([[w.value for w in widget[0]], \n",
    "              [w.value for w in widget[1]],\n",
    "              [w.value for w in widget[2]]])\n",
    "\n",
    "print('Input weights')\n",
    "print(W)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_lines(X, Y, W)\n",
    "plot_decision_contour(X, Y, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "* The three plots above shows the activation of the three neurons in the hidden layer. We can compute the activation of the hidden neuron $h_1$ as:\n",
    "$$ h_1 = \\tanh(w_{11}^{(1)} \\cdot x + w_{21}^{(1)} \\cdot y + w_{10}^{(1)}) $$\n",
    "Write down the the activate of the two other hidden units.\n",
    "\n",
    "* The expression you just wrote down can be simplified using vector notation and inner products. Given two vectors $a=[a_1, a_2]$ and $b=[b_1, b_2]$ then their inner product is given by $a\\cdot b = a^T b = a_1 b_1 + a_2 b_2$. Define a vector $\\textbf{x}$ and a vector $\\textbf{w}$ and write down the activation for the three hidden neurons using vector notation and inner products.\n",
    " \n",
    "* Adjust the components of the normal vector to find the plane that best seperates the red and the blue points in the 3D space\n",
    "\n",
    "* Based on the results printed in the bottom of the cell, compute the accuracy and error rate:\n",
    "$$ \\text{accuracy} = \\dfrac{\\text{number of correctly classified points}}{\\text{total number of points}} $$\n",
    "$$ \\text{error rate} = \\dfrac{\\text{number of wrongly classified points}}{\\text{total number of points}} $$\n",
    "what is the connection between the accuracy and error rate of an classifier?\n",
    "\n",
    "* Go back and try adjusting some of the weights. Can you optimize your classifier i.e. get a better accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "widget = widget2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell each time you update a value in the above widget\n",
    "N = np.array([n.value for n in widget])\n",
    "plot3d_space(X, Y, W, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional exercise: tensorflow playground\n",
    "The neural network percented here is very simple, but the principals hold for more complicated network. Try opening [tensorflow playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.30449&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) where we can play around with number of neurons in our network, activation function ect. Try out the following:\n",
    "- Can you recreate the network we have just investigated?\n",
    "- What happens with the decision boundary when we change activation function from $tanh(\\cdot)$ to $relu(\\cdot)$?\n",
    "- Try changing the dataset to the spiral. Can you find a network that can classify this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
