{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image.image_collection import Image_Collector, load_data,run_video_recognition\n",
    "from src.image.object_detection.custom_network import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Demo Notebook\n",
    "\n",
    "This notebook will lead you through multiple tasks dealing with applying deep learning to image recognition tasks. You will learn how to load and save images\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "- Explain and go through the basic process of training a neural network\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Getting started with recognizing objects in images\n",
    "\n",
    "In the cell below you can run a program that uses AI to recognize objects in images. Try to see if you can make it recognize some objects around you and perhaps find some objects that it can not detect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Program for object recognition.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment\n",
    "\n",
    "1. Using Python in the cell above, make sure the labels from the program are stored to a file.\n",
    "1. Select a number of object for testing the object recognition program.\n",
    "1. Run the program while showing it the object you selected. Make sure to show all the objects and to time (approximately) when you showed each of the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the experiment\n",
    "\n",
    "1. In the cell below, reload the file with the experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Make some kind of useful visualization, which they can easily access.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "run_video_recognition(model_name = \"mobilenet\", video_length=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 Object classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and take multiple pictures of five objects of your choice after labeling the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "collector= Image_Collector(num_pictures=1, num_objects=2)\n",
    "collector.run_collector()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We load a neural network to categorize your object pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "collector.show_images(model_name=\"mobilenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "1. How accurate are the labels for each object? Decide if one of the probable labels accurately describes the object and  count how many images are correct for each object. \n",
    "\n",
    "1. Are there differences in the accuracies for the objects? \n",
    "\n",
    "1. If yes, why do you think this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find a list of the categories used for training the neural network\n",
    "\n",
    "1. Do the categories reflect the environment you are in? \n",
    "\n",
    "1. Are there categories that you would not expect to encounter? \n",
    "\n",
    "1. Can you find an object  that you can not find in the categories? \n",
    "\n",
    "1. What do you expect to happen when you classify this object? Take pictures of the object and classify them? What does happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## 3 Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with four other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "\n",
    "You will go through the following basic steps of training an ML model:\n",
    "1. Obtain data\n",
    "1. Preprocess data\n",
    "1. (Decide on a fitting model)\n",
    "1. Train model\n",
    "1. Analyze model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Obtaining data\n",
    "\n",
    "- Find three other groups around you that you will work together with\n",
    "\n",
    "- Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n",
    "\n",
    "- Each of the groups takes ten pictures with their object in the picture and ten pictures without the object in the picture. \n",
    "    - Take care that your image is fully within the red frame \n",
    "    - Use different backgrounds for the pictures and rotate your object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "collector= Image_Collector()\n",
    "collector.run_collector(use_binary = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace FOLDERPATH in the following cell with the full path to the folder where you want your images to be saved\n",
    "    - Make sure that the folder exists and is empty. Due to the risk of accidentally deleting an important folder, you have to do this manually.\n",
    "    - On Windows, remember to double all the backslashes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = \"FOLDERPATH\"\n",
    "save_folder = \"C:\\\\Users\\\\lauri\\\\Documents\\\\test_folder\"\n",
    "collector.save_images(save_folder, use_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training the  classifier\n",
    "We will now create the classifier. We will use a simple neural network consisting of one dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_network = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the network is ready to start training on the data. First we will train the network for five epochs, meaning that we it will 'see' each image five times during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) =load_data(save_folder)\n",
    "custom_network.train((x_train, y_train), num_epochs =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the neural network we just trained on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_network.evaluate((x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the neural network to classify a live video feed. Evaluate how your model does with varying lighting conditions and backgrounds previously not encountered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "custom_network.run_live(video_length =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data augmentation\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in. This   is called *data augmentation*.\n",
    "\n",
    "- Run the cell below to see examples of your own images in the original and augmented version. Check if the images still\n",
    "    - look natural\n",
    "    - are different from your original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "collector.show_augmented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the training process while using augmented data. Do this by setting *use_augmentation* in the last cell of task *3.1* again and re-running the notebook from there.\n",
    "\n",
    "- How does the accuracy of your network change? \n",
    "- Is the live-demo more or less accurate with data augmentation? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sharing data\n",
    "Now you will collaborate with the other groups.\n",
    "\n",
    "- Exchange your object with one of the other groups. Compare the accuracy of your network on your own object vs. the other groups object by running the cells below and taking images of your own and the other object. Where is the accuracy better?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "compare_pics = Image_Collector(num_pictures=5)\n",
    "compare_pics.run_collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "compare_pics.show_images(net = custom_network.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of your classifier, you will share your data among groups. All of you upload your data in TODO and download all of the data into your image folder. Repeat the training process from *3.2 Training the  classifier*.\n",
    "- How does the accuracy and robustness of your classifier change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
