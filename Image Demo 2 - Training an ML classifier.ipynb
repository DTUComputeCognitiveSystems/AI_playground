{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.image.image_collection import Image_Collector, load_data,run_video_recognition\n",
    "from src.image.object_detection.custom_network import Classifier\n",
    "from notebooks.src.image_demos.demo_2 import DatasetAquisitionDashboard\n",
    "from src.real_time_plotting.KerasLearningPlotter import KerasLearningPlotter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "##  Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with four other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "\n",
    "You will go through the following basic steps of training an ML model:\n",
    "* Data preparation\n",
    "    * Obtain data\n",
    "    * Preprocess data\n",
    "    * Augment data\n",
    "* Data modelling\n",
    "    * Choose algorithm\n",
    "    * Train algorithm\n",
    "     \n",
    "* Evaluation\n",
    "    * Visualization of training\n",
    "    * Testing of edge cases\n",
    "    * Analyzing result\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain data\n",
    "\n",
    "* Find three other groups around you that you will work together with\n",
    "\n",
    "* Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n",
    "\n",
    "* Each of the groups takes ten pictures with their object in the picture and ten pictures without the object in the picture. \n",
    "    * Take care that part of your object is always in the red frame\n",
    "    * Use different backgrounds for the pictures and rotate your object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "data_dashboard = DatasetAquisitionDashboard()\n",
    "data_dashboard.start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "We will now create the classifier. We will use a simple neural network consisting of one dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "(x_train, y_train), (x_val, y_val) =load_data(os.path.join(data_dashboard.save_path.value,\"ml_images\"))\n",
    "\n",
    "my_net = Classifier()\n",
    "my_net.train((x_train, y_train), num_epochs =20,verbose = 0,callbacks=[KerasLearningPlotter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the neural network we just trained on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_net.evaluate((x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the neural network to classify a live video feed. Evaluate how your model does with varying lighting conditions and backgrounds previously not encountered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#widget\n",
    "%matplotlib qt5\n",
    "my_net.run_live(video_length =40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment data\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in. This   is called *data augmentation*.\n",
    "\n",
    "- Run the cell below to see examples of your own images in the original and augmented version. Check if the images still\n",
    "    - look natural\n",
    "    - are different from your original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data_dashboard.collector.show_augmented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the training process while using augmented data. Do this by checking \"Augmented\" and clicking on the save button again. After that, repeat the network training process.\n",
    "\n",
    "- How does the accuracy of your network change? \n",
    "- Is the live-demo more or less accurate with data augmentation? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain more data\n",
    "Now you will collaborate with the other groups.\n",
    "\n",
    "- Exchange your object with one of the other groups. Compare the accuracy of your network on your own object vs. the other groups object by running the cells below and taking images of your own and the other object. \n",
    "- Where is the accuracy better?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "#widget\n",
    "compare_pics = Image_Collector(num_pictures=5)\n",
    "compare_pics.run_collector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "compare_pics.show_images(net = my_net.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of your classifier, you will share your data among groups. All of you upload your data in the given dropbox folder and download all of the data into your image folder. Repeat the training process.\n",
    "\n",
    "- How does the accuracy and robustness of your classifier change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
