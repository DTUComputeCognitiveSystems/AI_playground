{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.image.image_collection import Image_Collector, load_data,run_video_recognition\n",
    "from src.image.object_detection.custom_network import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## 3 Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with four other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "\n",
    "You will go through the following basic steps of training an ML model:\n",
    "1. Obtain data\n",
    "1. Preprocess data\n",
    "1. (Decide on a fitting model)\n",
    "1. Train model\n",
    "1. Analyze model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Obtaining data\n",
    "\n",
    "- Find three other groups around you that you will work together with\n",
    "\n",
    "- Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n",
    "\n",
    "- Each of the groups takes ten pictures with their object in the picture and ten pictures without the object in the picture. \n",
    "    - Take care that your image is fully within the red frame \n",
    "    - Use different backgrounds for the pictures and rotate your object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "collector= Image_Collector()\n",
    "collector.run_collector(use_binary = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace FOLDERPATH in the following cell with the full path to the folder where you want your images to be saved\n",
    "    - Make sure that the folder exists and is empty. Due to the risk of accidentally deleting an important folder, you have to do this manually.\n",
    "    - On Windows, remember to double all the backslashes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = \"FOLDERPATH\"\n",
    "save_folder = \"C:\\\\Users\\\\lauri\\\\Documents\\\\test_folder\"\n",
    "collector.save_images(save_folder, use_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training the  classifier\n",
    "We will now create the classifier. We will use a simple neural network consisting of one dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_network = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the network is ready to start training on the data. First we will train the network for five epochs, meaning that we it will 'see' each image five times during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) =load_data(save_folder)\n",
    "custom_network.train((x_train, y_train), num_epochs =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the neural network we just trained on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_network.evaluate((x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the neural network to classify a live video feed. Evaluate how your model does with varying lighting conditions and backgrounds previously not encountered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "custom_network.run_live(video_length =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data augmentation\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in. This   is called *data augmentation*.\n",
    "\n",
    "- Run the cell below to see examples of your own images in the original and augmented version. Check if the images still\n",
    "    - look natural\n",
    "    - are different from your original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "collector.show_augmented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the training process while using augmented data. Do this by setting *use_augmentation* in the last cell of task *3.1* again and re-running the notebook from there.\n",
    "\n",
    "- How does the accuracy of your network change? \n",
    "- Is the live-demo more or less accurate with data augmentation? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sharing data\n",
    "Now you will collaborate with the other groups.\n",
    "\n",
    "- Exchange your object with one of the other groups. Compare the accuracy of your network on your own object vs. the other groups object by running the cells below and taking images of your own and the other object. Where is the accuracy better?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "compare_pics = Image_Collector(num_pictures=5)\n",
    "compare_pics.run_collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "compare_pics.show_images(net = custom_network.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of your classifier, you will share your data among groups. All of you upload your data in TODO and download all of the data into your image folder. Repeat the training process from *3.2 Training the  classifier*.\n",
    "- How does the accuracy and robustness of your classifier change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
