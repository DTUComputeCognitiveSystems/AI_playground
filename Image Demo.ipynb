{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.image.video.snapshot import VideoCamera\n",
    "from src.image.object_detection.keras_detector import KerasDetector\n",
    "from src.image.video.labelled import LabelledVideo\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Demo Notebook\n",
    "\n",
    "This notebook will lead you through multiple tasks dealing with applying deep learning to image recognition tasks. You will learn how to load and save images\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Recognizing objects in images/video\n",
    "\n",
    "In the cell below you can run a program that uses AI to recognize objects in images. Try to see if you can make it recognize some objects around you and perhaps find some objects that it can not detect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Program for object recognition.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this cell, the user should be able to write the labels from the object recognitions program to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment\n",
    "\n",
    "1. Using Python in the cell above, make sure the labels from the program are stored to a file.\n",
    "1. Select a number of object for testing the object recognition program.\n",
    "1. Run the program while showing it the object you selected. Make sure to show all the objects and to time (approximately) when you showed each of the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the experiment\n",
    "\n",
    "1. In the cell below, reload the file with the experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Make some kind of usefull visualization, which they can easily access.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = KerasDetector(model_name=\"mobilenet\",vegetarian = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "the_video = LabelledVideo(net,video_length=14 )\n",
    "the_video.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 Object classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and take multiple pictures of five objects of your choice after labeling the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "num_pictures_each = 5\n",
    "num_objects = 3\n",
    "num_labels_predicted = 4\n",
    "\n",
    "frames = []\n",
    "labels = []\n",
    "for i in range(num_objects):\n",
    "    label_name = input(\"Object label: \")\n",
    "    labels.append(label_name)\n",
    "\n",
    "    my_camera = VideoCamera(n_photos = num_pictures_each,title = \"Hold object before camera to take picture and press enter\", block = True)\n",
    "\n",
    "    my_camera.start()\n",
    "    frames.append(my_camera.photos[:num_pictures_each])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We load a neural network to categorize your object pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = KerasDetector(model_name=\"inception_resnet_v2\",n_labels_returned = num_labels_predicted, exlude_animals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "f, axarr = plt.subplots(num_objects, num_pictures_each, figsize=(4*num_pictures_each,3*num_objects))\n",
    "axarr=np.asarray(axarr) if num_objects ==1 and num_pictures_each==1 else axarr\n",
    "axarr = np.expand_dims(axarr, axis=0) if num_objects ==1 else axarr\n",
    "axarr =  np.expand_dims(axarr, axis=-1) if num_pictures_each ==1 else axarr\n",
    "\n",
    "for i in range (num_objects):\n",
    "    print(100*\"_\" +\"\\nObject {}\".format(labels[i]) )\n",
    "    for j in range(num_pictures_each):\n",
    "        if j==0:\n",
    "            axarr[i,j].set_ylabel(labels[i], rotation=0, size='large', labelpad=5*(len(labels[i])))\n",
    "        axarr[i,j].set_title(\"Picture {}\".format(j))\n",
    "        probable_labels=net.label_frame(frames[i][j])[0]\n",
    "        print(\"Picture {}: \".format(j),\", \".join(probable_labels))\n",
    "        axarr[i,j].imshow(frames[i][j])\n",
    "        axarr[i,j].tick_params( which='both', labelbottom=False,labelleft = False,length=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "1. How accurate are the labels for each object? Decide if one of the probable labels accurately describes the object and  count how many images are correct for each object. \n",
    "\n",
    "1. Are there differences in the accuracies for the objects? \n",
    "\n",
    "1. If yes, why do you think this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find a list of the categories used for training the neural network\n",
    "\n",
    "1. Do the categories reflect the environment you are in? \n",
    "\n",
    "1. Are there categories that you would not expect to encounter? \n",
    "\n",
    "1. Can you find an object  that you can not find in the categories? \n",
    "\n",
    "1. What do you expect to happen when you classify this object? Take pictures of the object and classify them? What does happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## 3 Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with two other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "- Find four other groups around you that you will work together with\n",
    "\n",
    "- Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "\n",
    "- Each of the groups takes ten pictures with their object in the picture and ten pictures without the object in the picture. \n",
    "    - Take care that your image is fully within the red frame \n",
    "    - Use different backgrounds for the pictures and rotate your object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "my_camera = VideoCamera(n_photos = 10,title = \"Hold object before camera to take picture and press enter\", block = True)\n",
    "my_camera.start()\n",
    "positive_frames = my_camera.photos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "my_camera = VideoCamera(n_photos = 10,title = \"Take pictures without the object by pressing enter\", block = True)\n",
    "my_camera.start()\n",
    "negative_frames = my_camera.photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cut all images to same size\n",
    "\n",
    "negative_frames = negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Replace FOLDERPATH in the following cell with the full path to the folder where you want your images to be saved\n",
    "    - On Windows, remember to double all the backslashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = \"FOLDERPATH\"\n",
    "save_folder = \"C:\\\\Users\\\\lauri\\\\Documents\\\\test_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in.\n",
    "\n",
    "This  common technique for preprocessing images is called *data augmentation*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_augmentations = 30\n",
    "for prefix, cur_list in zip([\"pos\", \"neg\"], [positive_frames, negative_frames]):\n",
    "    i = 0\n",
    "    for batch in datagen.flow(np.stack(cur_list),save_to_dir=save_folder, save_prefix=prefix, save_format='png'):\n",
    "        i += 1\n",
    "        if i > num_augmentations:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the folder you specified in the beginning. You should see many images with and without your object in it.\n",
    "\n",
    "- Now share your images with the other groups and also add their images to your folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier\n",
    "\n",
    "Now that we have created the dataset, we will train the image classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
