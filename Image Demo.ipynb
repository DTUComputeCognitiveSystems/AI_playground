{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.image.video.snapshot import VideoCamera\n",
    "from src.image.object_detection.keras_detector import KerasDetector, configure_simple_model\n",
    "from src.image.video.labelled import LabelledVideo\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\n",
    "import uuid\n",
    "from os import listdir\n",
    "import matplotlib.image as mpimg\n",
    "import keras\n",
    "from os.path import isfile, join\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Flatten, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.applications import densenet, vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from src.real_time.matplotlib_backend import MatplotlibLoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Demo Notebook\n",
    "\n",
    "This notebook will lead you through multiple tasks dealing with applying deep learning to image recognition tasks. You will learn how to load and save images\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Recognizing objects in images/video\n",
    "\n",
    "In the cell below you can run a program that uses AI to recognize objects in images. Try to see if you can make it recognize some objects around you and perhaps find some objects that it can not detect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Program for object recognition.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this cell, the user should be able to write the labels from the object recognitions program to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment\n",
    "\n",
    "1. Using Python in the cell above, make sure the labels from the program are stored to a file.\n",
    "1. Select a number of object for testing the object recognition program.\n",
    "1. Run the program while showing it the object you selected. Make sure to show all the objects and to time (approximately) when you showed each of the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the experiment\n",
    "\n",
    "1. In the cell below, reload the file with the experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Make some kind of usefull visualization, which they can easily access.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = KerasDetector(model_name=\"mobilenet\",exlude_animals=  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "the_video = LabelledVideo(net,video_length=14 )\n",
    "the_video.start()\n",
    "while(not the_video.real_time_backend.stop_now ):\n",
    "    plt.pause(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 Object classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and take multiple pictures of five objects of your choice after labeling the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "num_pictures_each = 2\n",
    "num_objects = 2\n",
    "num_labels_predicted = 4\n",
    "\n",
    "frames = []\n",
    "labels = []\n",
    "for i in range(num_objects):\n",
    "    label_name = input(\"Object label: \")\n",
    "    labels.append(label_name)\n",
    "    back_end = MatplotlibLoop()\n",
    "    my_camera = VideoCamera(n_photos = num_pictures_each, backend=back_end, title = \"Hold object before camera to take picture and press enter\")\n",
    "\n",
    "    my_camera.start()\n",
    "    while(not my_camera.real_time_backend.stop_now ):\n",
    "        plt.pause(.5)\n",
    "\n",
    "    \n",
    "    frames.append(my_camera.photos[:num_pictures_each])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We load a neural network to categorize your object pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = KerasDetector(model_name=\"inception_resnet_v2\",n_labels_returned = num_labels_predicted, exlude_animals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "f, axarr = plt.subplots(num_objects, num_pictures_each, figsize=(4*num_pictures_each,3*num_objects))\n",
    "axarr=np.asarray(axarr) if num_objects ==1 and num_pictures_each==1 else axarr\n",
    "axarr = np.expand_dims(axarr, axis=0) if num_objects ==1 else axarr\n",
    "axarr =  np.expand_dims(axarr, axis=-1) if num_pictures_each ==1 else axarr\n",
    "\n",
    "for i in range (num_objects):\n",
    "    print(100*\"_\" +\"\\nObject {}\".format(labels[i]) )\n",
    "    for j in range(num_pictures_each):\n",
    "        if j==0:\n",
    "            axarr[i,j].set_ylabel(labels[i], rotation=0, size='large', labelpad=5*(len(labels[i])))\n",
    "        axarr[i,j].set_title(\"Picture {}\".format(j))\n",
    "        probable_labels=net.label_frame(frames[i][j])[0]\n",
    "        print(\"Picture {}: \".format(j),\", \".join(probable_labels))\n",
    "        axarr[i,j].imshow(frames[i][j])\n",
    "        axarr[i,j].tick_params( which='both', labelbottom=False,labelleft = False,length=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "1. How accurate are the labels for each object? Decide if one of the probable labels accurately describes the object and  count how many images are correct for each object. \n",
    "\n",
    "1. Are there differences in the accuracies for the objects? \n",
    "\n",
    "1. If yes, why do you think this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find a list of the categories used for training the neural network\n",
    "\n",
    "1. Do the categories reflect the environment you are in? \n",
    "\n",
    "1. Are there categories that you would not expect to encounter? \n",
    "\n",
    "1. Can you find an object  that you can not find in the categories? \n",
    "\n",
    "1. What do you expect to happen when you classify this object? Take pictures of the object and classify them? What does happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## 3 Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with four other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "- Find four other groups around you that you will work together with\n",
    "\n",
    "- Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "\n",
    "- Each of the groups takes ten pictures with their object in the picture and ten pictures without the object in the picture. \n",
    "    - Take care that your image is fully within the red frame \n",
    "    - Use different backgrounds for the pictures and rotate your object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib auto\n",
    "#TODO make loop\n",
    "my_camera = VideoCamera(n_photos = 10,title = \"Hold object before camera to take picture and press enter\", block = True)\n",
    "my_camera.start()\n",
    "while(not my_camera.real_time_backend.stop_now ):\n",
    "    plt.pause(.5)\n",
    "positive_frames = my_camera.photos\n",
    "my_camera = VideoCamera(n_photos = 10,title = \"Take pictures without the object by pressing enter\", block = True)\n",
    "while(not my_camera.real_time_backend.stop_now ):\n",
    "    plt.pause(.5)\n",
    "negative_frames = my_camera.photos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Replace FOLDERPATH in the following cell with the full path to the folder where you want your images to be saved\n",
    "    - On Windows, remember to double all the backslashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = \"FOLDERPATH\"\n",
    "save_folder = \"/home/lauri/data/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in.\n",
    "\n",
    "This  common technique for preprocessing images is called *data augmentation*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  TODO later do augmentation on our own\n",
    "# right now use keras\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_augmentations = 36\n",
    "for prefix, cur_list in zip([\"pos\", \"neg\"], [positive_frames, negative_frames]):\n",
    "    i = 0\n",
    "    for batch in datagen.flow(np.stack(cur_list)[:, :224, :224],save_to_dir=save_folder, save_prefix=prefix, save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > num_augmentations:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the folder you specified in the beginning. You should see many images with and without your object in it.\n",
    "\n",
    "- Now share your images with the other groups and also add their images to your folder\n",
    "\n",
    "### Preprocessing the data \n",
    "- Load the images and normalize them\n",
    "- Save the mean and standard deviation used to normalize the image so you can preprocess future images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of the positive and negative images \n",
    "positive_img_files = [f for f in listdir(save_folder) if isfile(join(save_folder, f)) and \"pos\" in f]\n",
    "negative_img_files = [f for f in listdir(save_folder) if isfile(join(save_folder, f)) and \"neg\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the images \n",
    "positive_imgs = np.stack (mpimg.imread(join(save_folder, file_name)) for file_name in positive_img_files)\n",
    "neg_imgs = np.stack (mpimg.imread(join(save_folder, file_name)) for file_name in negative_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create your dataset \n",
    "x = np.vstack([positive_imgs, neg_imgs])\n",
    "y = np.hstack([np.ones((len(positive_imgs))), np.zeros((len(neg_imgs)))])\n",
    "y = to_categorical(y, num_classes= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we simply have a list of images where the first half of them contains your object and the second one does not. We will shuffle the list, so that they are more randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_permuation = np.random.permutation(len(y))\n",
    "x = x[random_permuation]\n",
    "y= y[random_permuation]\n",
    "x = preprocess_input(x)\n",
    "x_train = x[:int(0.8*len(x))]\n",
    "y_train = y[:int(0.8*len(x))]\n",
    "x_test = x[int(0.8*len(x)): int(0.9*len(x)) ]\n",
    "y_test = y[int(0.8*len(x)): int(0.9*len(x)) ]\n",
    "x_val = x[int(0.9*len(x)):]\n",
    "y_val = y[int(0.9*len(x)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier\n",
    "\n",
    "Now we are ready to create the classifier and train it. We will use a pre-trained neural network and fine-tune it with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(input_shape=(224, 224,3),include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Flatten()(base_model.output)\n",
    "w = Dense(1024, activation='relu')(w)\n",
    "w = Dropout(0.5)(w)\n",
    "\n",
    "predictions = Dense(2, activation = 'softmax')(w)\n",
    "\n",
    "#create graph of your new model\n",
    "head_model = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "\n",
    "head_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head_model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
