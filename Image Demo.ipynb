{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image.video import VideoWText\n",
    "import matplotlib.pyplot as plt\n",
    "from src.image.video.snapshot import VideoCamera\n",
    "from src.image.object_detection.keras_detector import KerasDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Demo\n",
    "\n",
    "WELCOME MESSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing objects in images/video\n",
    "\n",
    "In the cell below you can run a program that uses AI to recognize objects in images. Try to see if you can make it recognize some objects around you and perhaps find some objects that it can not detect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Program for object recognition.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this cell, the user should be able to write the labels from the object recognitions program to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment\n",
    "\n",
    "1. Using Python in the cell above, make sure the labels from the program are stored to a file.\n",
    "1. Select a number of object for testing the object recognition program.\n",
    "1. Run the program while showing it the object you selected. Make sure to show all the objects and to time (approximately) when you showed each of the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the experiment\n",
    "\n",
    "1. In the cell below, reload the file with the experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Make some kind of usefull visualization, which they can easily access.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "the_video = VideoWText(\n",
    "    record_frames=True, \n",
    "    frame_rate=15, \n",
    "    seconds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysing the experiment\n",
    "\n",
    "1. In the cell below, reload the file with the experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "num_pictures_each = 3\n",
    "num_objects = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and take multiple pictures of five objects of your choice after labeling the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "labels = []\n",
    "for i in range(num_objects):\n",
    "    label_name = input(\"Object label: \")\n",
    "    labels.append(label_name)\n",
    "\n",
    "    my_camera = VideoCamera(seconds=10, title = \"Hold object before camera to take picture and press enter\")\n",
    "    frames.append(my_camera.photos[:num_pictures_each])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a neural network to categorize your object pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = KerasDetector(model_name=\"mobilenet\",n_labels_returned = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "f, axarr = plt.subplots(num_objects, num_pictures_each, figsize=(3*num_pictures_each,3*num_objects))\n",
    "for i in range (num_objects):\n",
    "\n",
    "    print(\"\\nObject {}\".format(labels[i]))\n",
    "\n",
    "    for j in range(num_pictures_each):\n",
    "        if i ==0:\n",
    "            axarr[i,j].set_title(\"Picture {}\".format(j))\n",
    "        #predict labels\n",
    "        probable_labels=net.label_frame(frames[i][j])[0]\n",
    "        print(\"Picture {}: \".format(j),probable_labels)\n",
    "\n",
    "        #axarr[i,j].axis('off')\n",
    "        axarr[i,j].imshow(frames[i][j])\n",
    "   \n",
    "\n",
    "        axarr[i,j].tick_params( which='both', labelbottom=False,labelleft = False,length=0)\n",
    "\n",
    "        if j==0:\n",
    "            axarr[i,j].set_ylabel(labels[i], rotation=0, size='large', labelpad=4*(len(labels[i])))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate are the labels for each object (decide if one of the probable labels accurately describes the object and and count how many images are correct for each object. \n",
    "\n",
    "Are there differences in the accuracies for the objects? Why do you think this happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.label_frame(frames[i][j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
