{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('..')\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    os.chdir(Path.cwd().parent.resolve())\n",
    "print(\"Working directory: {}\".format(Path.cwd()))\n",
    "\n",
    "from src.image.image_collection import ImageCollector, load_data\n",
    "from src.image.object_detection.custom_network import Classifier\n",
    "from notebooks.src.image_demos.demo_2 import TwoClassCameraDashboard\n",
    "from src.real_time_plotting.KerasLearningPlotter import KerasLearningPlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "##  Image Demo 2 - Training an ML classifier\n",
    "\n",
    "In this exercise you will collaborate with four other groups to design and create a classifier for a common object of your choice. The classifier should be able to detect whether the object is in a picture.\n",
    "\n",
    "\n",
    "You will go through the following basic steps of training an ML model:\n",
    "* Data preparation\n",
    "    * Obtain data\n",
    "    * Preprocess data\n",
    "    * Augment data\n",
    "* Data modelling\n",
    "    * Choose algorithm\n",
    "    * Train algorithm\n",
    "     \n",
    "* Evaluation\n",
    "    * Visualization of training\n",
    "    * Testing of edge cases\n",
    "    * Analyzing result\n",
    " \n",
    "![ML framework](figures\\ml_framework.PNG \"ML framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain data\n",
    "\n",
    "* Find three other groups around you that you will work together with\n",
    "\n",
    "* Agree on a common object that all of you have in your possession (e.g. a pen, glasses, a coffe cup)\n",
    "\n",
    "* Each of the groups takes ten pictures *with their object* and ten pictures *without the object*. \n",
    "    * Take care that part of your object is always in the red frame\n",
    "    * Use different backgrounds for the pictures and rotate your object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "data_dashboard = TwoClassCameraDashboard()\n",
    "data_dashboard.start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "We will now create the classifier. We will use a simple neural network consisting of one dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "(x_train, y_train), (x_val, y_val) =load_data(os.path.join(data_dashboard.save_path.value,\"ml_images\"))\n",
    "my_net = Classifier()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    my_net.train((x_train, y_train), num_epochs =10,verbose = 0,callbacks=[KerasLearningPlotter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two diagrams above show the accuracy of the neural network during the training as well as the average loss, i.e. \n",
    "how 'bad' the neural network did according to the self chosen quality metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the neural network we just trained on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_net.evaluate((x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the neural network to classify a live video feed. Evaluate how your model does with varying lighting conditions and backgrounds previously not encountered. \n",
    "\n",
    "Do five tests of each condition and calculate the accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "my_net.run_live(video_length =40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*double click here to edit cell*\n",
    "\n",
    "\n",
    "|  | Normal light | Darker | Brighter | Noisy background |  \n",
    "| --- | --- | --- |--- |--- |--- |\n",
    "| # correct | 0 | 0 |0 | 0| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What can you conclude on the stability of your algorithm when encountering conditions not in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment data\n",
    "We can increase the number of training images for the classifier by using our knowledge about images. If an image is flipped or slightly rotated, it will most likely still display the same object but for our classifier look entirely different. \n",
    "\n",
    "This can be exploited by adding the flipped image and slightly rotated versions of the same image to the dataset dataset. In our case, this will increase the number of training images ten times while not increasing the amount of work we have to put in. This   is called *data augmentation*.\n",
    "\n",
    "- Run the cell below to see examples of your own images in the original and augmented version. Check if the images still\n",
    "    - look natural\n",
    "    - are different from your original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data_dashboard.collector.show_augmented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the training process while using augmented data. Do this by checking \"Augmented\" and clicking on the save button again. After that, repeat the network training process.\n",
    "\n",
    "- How does the accuracy of your network change? \n",
    "- Is the live-demo more or less accurate with data augmentation? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain more data\n",
    "Now you will collaborate with the other groups.\n",
    "\n",
    "- Exchange your object with one of the other groups. Compare the accuracy of your network on your own object vs. the other groups object by running the cells below and taking images of your own and the other object. \n",
    "- Do you obtain better accuracy on your own object or on the other group's object?\n",
    "- What can you conclude on the importance of variety while collecting data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "compare_pics = ImageCollector(num_pictures=5)\n",
    "compare_pics.run_collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "compare_pics.show_images(net = my_net.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of your classifier, you will share your data among groups. All of you upload your data in the given dropbox folder and download all of the data into your image folder. Repeat the training process.\n",
    "\n",
    "- How does the accuracy and robustness of your classifier change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
