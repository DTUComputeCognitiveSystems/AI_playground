{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tekstanalyse demo med kunstintelligens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height: 10000px;\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import alle moduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import io # Read the prime-minister's speech file with UTF-8 encoding\n",
    "import glob # Read the prime minister's speech files in a directory\n",
    "import pandas as pd # Displaying results in a data-frame\n",
    "import requests # Used to search wikipedia for the articles\n",
    "import urllib.parse # Used to URL-encode the query strings\n",
    "\n",
    "import matplotlib # Plotting\n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import numpy as np # Plotting\n",
    "\n",
    "from scipy.interpolate import spline # Smoothing matplotlib graphs\n",
    "from afinn import Afinn # Sentiment analysis package\n",
    "from IPython.core.display import display#, HTML # HTML displayer\n",
    "from ipywidgets.widgets import Accordion, HTML, interact_manual\n",
    "from notebooks.exercises.src.text.rsspedia import Rsspedia # Searching in Wiki for text matches using Okapi BM25\n",
    "from notebooks.exercises.src.text.news_sentiment_1 import RSSDashboard\n",
    "from notebooks.exercises.src.text.news_sentiment_2 import PrimeMinisterSpeechDashboard\n",
    "from src.text.document_retrieval.wikipedia import Wikipedia # Generic Wikipedia class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 1: Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kan vælge mellem forskellige danske nyhedskilder og se de sidste nyheder med deres sentiment-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RSSdb = RSSDashboard()\n",
    "#display(RSSdashboard.widget_box)\n",
    "\n",
    "def ff(i):\n",
    "    RSSdb._do_sentiment_analysis(selected_value = i)\n",
    "    \n",
    "interact_manual(ff, i = RSSdb.select);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 2: relevante Wikipedia sider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the wikipedia class and (down)load the vocabulary\n",
    "wikipedia = Wikipedia(language=\"danish\", cache_directory_url=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the class to search RSS titles in the Wikipedia\n",
    "rsspedia = Rsspedia(wikipedia)\n",
    "rsspedia.search_wikipedia(RSSdb.data_titles)\n",
    "\n",
    "list_labels = []\n",
    "for i in range(len(RSSdb.data_titles)):\n",
    "    list_labels.append(HTML(value = rsspedia.search_results[i]))\n",
    "\n",
    "accordion = Accordion(children = (list_labels),)\n",
    "\n",
    "for i in range(len(RSSdb.data_titles)):\n",
    "    accordion.set_title(i, \"{}. {}\".format(i + 1, RSSdb.data_titles[i]))\n",
    "\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 3: relevante Wikipedia sider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dasem.wikipedia import ExplicitSemanticAnalysis\n",
    "esa = ExplicitSemanticAnalysis()\n",
    "#import nltk #nltk.download('punkt')\n",
    "content_items = []\n",
    "n_wiki_results = 3\n",
    "\n",
    "for i in range(len(RSSdb.data_titles)):\n",
    "    urls = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    list_labels = esa.related(RSSdb.data_titles[i].lower(), n = n_wiki_results)\n",
    "    for j in range(n_wiki_results):\n",
    "        url = \"https://da.wikipedia.org/w/api.php?action=query&prop=extracts&exintro&titles={}&format=json&redirects\" \\\n",
    "              .format(urllib.parse.quote_plus(list_labels[0][j].replace(\" \",\"_\")))\n",
    "        json_content = requests.get(url).json()\n",
    "        content_item = next(iter(json_content[\"query\"][\"pages\"].values()))\n",
    "        urls.append(url)\n",
    "        titles.append(content_item[\"title\"])\n",
    "        abstracts.append(content_item[\"extract\"])\n",
    "    content_items.append(HTML(value = \"{}{}\".format(list_labels[0], rsspedia.display_beautifully(titles, abstracts, urls))))\n",
    "\n",
    "accordion = Accordion(children = (content_items),)\n",
    "\n",
    "for i in range(len(RSSdb.data_titles)):\n",
    "    accordion.set_title(i, \"{}. {}\".format(i + 1, RSSdb.data_titles[i]))\n",
    "\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentanalyse af statsministeren's tale\n",
    "Statsministerens tale ved Folketingets åbning gennem år"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "afinn = Afinn(language = \"da\")\n",
    "speeches = {}\n",
    "speeches_sentiments = {}\n",
    "for filepath in glob.iglob('data/statsminister/*.txt'):\n",
    "    speeches[os.path.basename(filepath).replace(\".txt\",\"\")] = [line.rstrip('\\n') for line in open(filepath, mode=\"r\", encoding=\"utf-8\")]\n",
    "    current_sentiment = 0\n",
    "    for line in speeches[os.path.basename(filepath).replace(\".txt\",\"\")]:\n",
    "        current_sentiment += afinn.score(line)\n",
    "    speeches_sentiments[os.path.basename(filepath).replace(\".txt\",\"\")] = current_sentiment\n",
    "\n",
    "lists = sorted(speeches_sentiments.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.ylim(bottom = -50, top = 300)\n",
    "xposition = [5, 12, 14, 18]\n",
    "for xc in xposition:\n",
    "    plt.axvline(x = xc, color='k', linestyle='--')\n",
    "ax.tick_params(labelsize = 13)\n",
    "ax.plot(x, y, color=\"black\", linewidth = 4)\n",
    "ax.set_xlabel('År', fontsize=16)\n",
    "ax.set_ylabel('Sentiment', fontsize=15)\n",
    "ax.set_title('Statsministeren\\'s tale sentiment', fontsize=18)\n",
    "\n",
    "plt.text(19, -40, \"Lars Løkke Rasmussen\", size=15, rotation=90., ha=\"center\", va=\"bottom\",\n",
    "         bbox=dict(boxstyle=\"round\", ec=(0.5, 0.5, 1), fc=(0.8, 0.8, 1),))\n",
    "plt.text(15, -40, \"Helle Thoring-Schmidt\", size=15, rotation=90., ha=\"center\", va=\"bottom\",\n",
    "         bbox=dict(boxstyle=\"round\", ec=(0.5, 1, 0.5), fc=(0.8, 1, 0.8),))\n",
    "plt.text(13, -40, \"Lars Løkke Rasmussen\", size=15, rotation=90., ha=\"center\", va=\"bottom\",\n",
    "         bbox=dict(boxstyle=\"round\", ec=(0.5, 0.5, 1), fc=(0.8, 0.8, 1),))\n",
    "plt.text(6, -40, \"Anders Fogh Rasmussen\", size=15, rotation=90., ha=\"center\", va=\"bottom\",\n",
    "         bbox=dict(boxstyle=\"round\", ec=(1, 0.5, 0.5), fc=(1, 0.8, 0.8),))\n",
    "plt.text(0, -40, \"Poul Nyrup Rasmussen\", size=15, rotation=90., ha=\"center\", va=\"bottom\",\n",
    "         bbox=dict(boxstyle=\"round\", ec=(0.5, 0.5, 0.5), fc=(0.8, 0.8, 0.8),))\n",
    "\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pmSpeechDashboard = PrimeMinisterSpeechDashboard()\n",
    "pmSpeechDashboard.load_speeches()\n",
    "\n",
    "def f(i):\n",
    "    pmSpeechDashboard._do_sentiment_analysis(speech_number = i, use_exp_smoothing = False)\n",
    "    \n",
    "interact_manual(f, i = pmSpeechDashboard.select);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
