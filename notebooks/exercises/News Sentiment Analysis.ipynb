{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tekstanalyse demo med kunstintelligens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import alle moduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io # Read the prime-minister's speech file with UTF-8 encoding\n",
    "import glob # Read the prime minister's speech files in a directory\n",
    "import pandas as pd # Displaying results in a data-frame\n",
    "import requests # Used to search wikipedia for the articles\n",
    "import urllib.parse # Used to URL-encode the query strings\n",
    "\n",
    "import matplotlib # Plotting\n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import numpy as np # Plotting\n",
    "\n",
    "from scipy.interpolate import spline # Smoothing matplotlib graphs\n",
    "from afinn import Afinn # Sentiment analysis package\n",
    "from IPython.core.display import display#, HTML # HTML displayer\n",
    "from ipywidgets.widgets import Accordion, HTML\n",
    "from notebooks.exercises.src.text.rsspedia import Rsspedia # Searching in Wiki for text matches using Okapi BM25\n",
    "from notebooks.exercises.src.text.news_sentiment_1 import RSSDashboard\n",
    "from notebooks.exercises.src.text.news_sentiment_2 import PrimeMinisterSpeechDashboard\n",
    "from src.text.document_retrieval.wikipedia import Wikipedia # Generic Wikipedia class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 1: Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kan vælge mellem forskellige danske nyhedskilder og se de sidste nyheder med deres sentiment-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSSdashboard = RSSDashboard()\n",
    "display(RSSdashboard.widget_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 2: relevante Wikipedia sider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the wikipedia class and (down)load the vocabulary\n",
    "wikipedia = Wikipedia(language=\"danish\", cache_directory_url=None)\n",
    "# Initialize the class to search RSS titles in the Wikipedia\n",
    "rsspedia = Rsspedia(wikipedia)\n",
    "rsspedia.search_wikipedia(RSSdashboard.data_titles)\n",
    "\n",
    "list_labels = []\n",
    "for i in range(len(RSSdashboard.data_titles)):\n",
    "    list_labels.append(HTML(value = rsspedia.search_results[i]))\n",
    "\n",
    "accordion = Accordion(children = (list_labels),)\n",
    "\n",
    "for i in range(len(RSSdashboard.data_titles)):\n",
    "    accordion.set_title(i, \"{}. {}\".format(i + 1, RSSdashboard.data_titles[i]))\n",
    "\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nyhedsanalyse 3: relevante Wikipedia sider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dasem.wikipedia import ExplicitSemanticAnalysis\n",
    "esa = ExplicitSemanticAnalysis()\n",
    "#import nltk #nltk.download('punkt')\n",
    "content_items = []\n",
    "n_wiki_results = 3\n",
    "\n",
    "for i in range(len(RSSdashboard.data_titles)):\n",
    "    urls = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    list_labels = esa.related(RSSdashboard.data_titles[i].lower(), n = n_wiki_results)\n",
    "    for j in range(n_wiki_results):\n",
    "        url = \"https://da.wikipedia.org/w/api.php?action=query&prop=extracts&exintro&titles={}&format=json&redirects\".format(urllib.parse.quote_plus(list_labels[0][j].replace(\" \",\"_\")))\n",
    "        json_content = requests.get(url).json()\n",
    "        content_item = next(iter(json_content[\"query\"][\"pages\"].values()))\n",
    "        urls.append(url)\n",
    "        titles.append(content_item[\"title\"])\n",
    "        abstracts.append(content_item[\"extract\"])\n",
    "    content_items.append(HTML(value = \"{}{}\".format(list_labels[0], rsspedia.display_beautifully(titles, abstracts, urls))))\n",
    "\n",
    "accordion = Accordion(children = (content_items),)\n",
    "\n",
    "for i in range(len(RSSdashboard.data_titles)):\n",
    "    accordion.set_title(i, \"{}. {}\".format(i + 1, RSSdashboard.data_titles[i]))\n",
    "\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentanalyse af statsministeren's tale\n",
    "Statsministerens tale ved Folketingets åbning gennem år"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = {}\n",
    "speeches_sentiments = {}\n",
    "for filepath in glob.iglob('data/statsminister/*.txt'):\n",
    "    speeches[os.path.basename(filepath).replace(\".txt\",\"\")] = [line.rstrip('\\n') for line in open(filepath, mode=\"r\", encoding=\"utf-8\")]\n",
    "    current_sentiment = 0\n",
    "    for line in speeches[os.path.basename(filepath).replace(\".txt\",\"\")]:\n",
    "        current_sentiment += afinn.score(line)\n",
    "    speeches_sentiments[os.path.basename(filepath).replace(\".txt\",\"\")] = current_sentiment\n",
    "\n",
    "lists = sorted(speeches_sentiments.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.plot(x, y, color=\"black\")\n",
    "ax.set(xlabel='Tid', ylabel='Sentiment', title=\"Statsministeren's tale sentiment\")\n",
    "\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_speech = \"2018\"\n",
    "afinn = Afinn(language = \"da\")\n",
    "scores = []\n",
    "for i in range(len(speeches[\"2018\"])):\n",
    "    scores.append(afinn.score(speeches[\"2018\"][i]))\n",
    "\n",
    "# Dataframe\n",
    "pd.set_option('display.max_colwidth', -1) # Used to display whole title (non-truncated)\n",
    "df = pd.DataFrame({\"Line\": speeches[\"2018\"], \"Score\": scores}) # Creating the data frame and populating it\n",
    "\n",
    "# Highlight the positive and negative sentiments\n",
    "def highlight(s):\n",
    "    if s.Score > 0:\n",
    "        return ['background-color: #AAFFAA']*2\n",
    "    elif s.Score < 0:\n",
    "        return ['background-color: #FFAAAA']*2\n",
    "    else:\n",
    "        return ['background-color: #FFFFFF']*2\n",
    "\n",
    "df = df.style.apply(highlight, axis=1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_scores = []\n",
    "smoothed_scores.append(scores[0])\n",
    "smoothing_constant = 0.3\n",
    "number_of_averaged_scores = 10\n",
    "for i in range(len(scores) - 1):\n",
    "    s = 0\n",
    "    for j in range(number_of_averaged_scores):\n",
    "        if j == 0:\n",
    "            s = scores[i - j] * smoothing_constant\n",
    "        elif i - j >= 0:\n",
    "            s = s + scores[i - j] * (1 - smoothing_constant / number_of_averaged_scores)        \n",
    "    smoothed_scores.append(s)\n",
    "\n",
    "# Data for plotting\n",
    "y = np.array(smoothed_scores)\n",
    "x = np.array(range(1, len(smoothed_scores) + 1))\n",
    "x_s = np.linspace(x.min(),x.max(), 1800) #300 represents number of points to make between T.min and T.max\n",
    "y_s = spline(x, y, x_s)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.plot(x_s, y_s, color=\"black\")\n",
    "ax.set(xlabel='Tid', ylabel='Sentiment', title=\"Statsministeren's tale sentiment\")\n",
    "\n",
    "# use xnew, ynew to plot filled-color graphs\n",
    "plt.fill_between(x_s, 0, y_s, where=(y_s-1) < -1 , color='red')\n",
    "plt.fill_between(x_s, 0, y_s, where=(y_s-1) > -1 , color='green')\n",
    "\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeMinisterSpeechDashboard = PrimeMinisterSpeechDashboard\n",
    "primeMinisterSpeechDashboard.load_speeches()\n",
    "display(primeMinisterSpeechDashboard.widget_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
