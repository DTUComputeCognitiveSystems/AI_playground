{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run global setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run local setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.rl.NatureDQN import NatureDQN\n",
    "from src.rl.AtariAgent import AtariAgent\n",
    "from src.rl.util import run_episode\n",
    "import gym\n",
    "\n",
    "config = {'conv_layers': 3,\n",
    "          'conv_units': [32, 64, 64],\n",
    "          'filter_sizes': [8, 4, 3],\n",
    "          'strides': [4, 2, 1],\n",
    "          'state_frames': 4,\n",
    "          'fc_layers': 1,\n",
    "          'fc_units': [512],\n",
    "          'in_width': 84,\n",
    "          'in_height': 84,\n",
    "          'discount': 0.99,\n",
    "          'device': '/gpu:0',\n",
    "          'lr': 0.00025,\n",
    "          'opt_decay': 0.95,\n",
    "          'momentum': 0.0,\n",
    "          'opt_eps': 0.01,\n",
    "          'clip_delta': 1.0,\n",
    "          'tensorboard': False,\n",
    "          'tensorboard_freq': 50,\n",
    "          'ckpt': 0,\n",
    "          'random_seed': 42,\n",
    "          'hist_size': 1e6,\n",
    "          'batch_size': 32,\n",
    "          'eps': 1.0,\n",
    "          \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-v4')\n",
    "config['num_actions'] = env.action_space.n\n",
    "net = NatureDQN(config)\n",
    "#net.load('src/rl/trained/breakout')\n",
    "agent = AtariAgent(env, net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_episode(env, agent, render=True, render_delay=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(env, agent, epsilon_decay, n_episodes) -> list:\n",
    "    rewards = []\n",
    "    for i in tqdm(range(n_episodes)):\n",
    "        agent.reset()\n",
    "        sum_r = run_episode(env, agent, learn=True)\n",
    "        rewards.append(sum_r)\n",
    "        agent.eps *= epsilon_decay\n",
    "        if i % 1e4 == 0:\n",
    "            print(\"Episode \", i, \" reward: \", sum_r)\n",
    "            agent.sync_target()\n",
    "    agent.epsilon = 0\n",
    "    sum_r = run_episode(env, agent)\n",
    "    print('Trained for ', n_episodes, ' episodes. Last episode achieved a reward of ', sum_r)     \n",
    "    return rewards\n",
    "\n",
    "\n",
    "run_experiment(env, agent, 9e-7, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
