{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "This notebook will introduce you to word-embeddings. An embedding is essentially a vector-representation for some object or concept - in this case words. Word embeddings can be trained to create these vector for a given vocabulary, and the vectors can then be used by other systems for performing AI-tasks. Word embeddings is an ongoing field of research and many new ideas appear every year.  \n",
    "\n",
    "The specific type of word embeddings which we will use here is called fastText and has been developed by Facebook. They \n",
    "have pretrained embeddings freely available, so we do not need to train them ourselves, but we can simply download theirs and work from there.\n",
    "\n",
    "#### Global Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text.word_embedding.fast_text_usage import get_fasttext_model\n",
    "from notebooks.exercises.src.text import word_embedding_viz\n",
    "from notebooks.exercises.src.text import fasttext_document_visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText model\n",
    "\n",
    "Here we load the fastText model. You will have to download it if you haven't already, and the cell below will instruct you on where to find it. When the data is downloaded, fastText will be loaded into memory, which will also take a couple of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting FastText data.\n",
      "Data for FastText not found. \n",
      "It can be downloaded from https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip. \n",
      "Do you want to download this file now? - Note that this is a LARGE file.\n",
      "[y/N]y\n",
      "Downloading:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0898965e8e4dcba89e93dc0807fd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10356881291), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving to file\n",
      "File downloaded.\n",
      "Getting FastText data.\n",
      "\tUsing zip file.\n",
      "\tUnzipping into temporary file: C:\\Users\\anfro\\AppData\\Local\\Temp\\tmpgvbx1uz9\n",
      "\tLoading model from temporary file.\n",
      "\tRemoving temporary file.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "fastText: Cannot load C:\\Users\\anfro\\AppData\\Local\\Temp\\tmpgvbx1uz9 due to C++ extension failed to allocate the memory",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "RuntimeError                              Traceback (most recent call last)",
      "fasttext\\fasttext.pyx in fasttext.fasttext.load_model()\n",
      "RuntimeError: vector<T> too long",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "Exception                                 Traceback (most recent call last)",
      "<ipython-input-4-591d5a043caa> in <module>()\n----> 1 fasttext_model = get_fasttext_model(lang=\"en\")\n",
      "~\\Documents\\GitHub\\AI_playground\\src\\text\\word_embedding\\fast_text_usage.py in get_fasttext_model(lang)\n     64         # Check if downloaded\n     65         if downloaded:\n---> 66             model = get_fasttext_model(lang=lang)\n     67 \n     68         else:\n",
      "~\\Documents\\GitHub\\AI_playground\\src\\text\\word_embedding\\fast_text_usage.py in get_fasttext_model(lang)\n     39                 # Pass temporary file to fasttext\n     40                 print(\"\\tLoading model from temporary file.\")\n---> 41                 model = fastText.load_model(temp_file.name)\n     42 \n     43             # Delete temporary file\n",
      "fasttext\\fasttext.pyx in fasttext.fasttext.load_model()\n",
      "Exception: fastText: Cannot load C:\\Users\\anfro\\AppData\\Local\\Temp\\tmpgvbx1uz9 due to C++ extension failed to allocate the memory"
     ]
    }
   ],
   "source": [
    "fasttext_model = get_fasttext_model(lang=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "We will now look at a ton of word-vectors. The vectors are in 300 dimensions! This is way too many dimensions for a human to visualize geometrically. We can though compute something called a Principle Component Analysis (PCA). You will later learn a ton about this method, but in short terms it allows us to find the few dimensions with the most variance in (the most movement of the vectors and the most \"action\" to see). If we take the 3 dimensions with the most variance we can plot them in a 3D plot!  \n",
    "\n",
    "Let's try that!  \n",
    "Below you can randomly sample some words and plot then in 3D PCA space.  \n",
    "Watch out and don't pick too many samples! - your computer probably wont be able to handle it ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualizer  = word_embedding_viz.CompleteWordEmbeddingVisualizer(fasttext_model=fasttext_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so this is definitely way too many words and dimensions for us to understand!  \n",
    "Let's therefore look into some specific words in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into specific words\n",
    "Below to take out 2 dimensions based on the vectors between points.  \n",
    "\n",
    "There are a couple of categories below which you can in investigate and you can include/exclude rows and column the table for the plot. You can also select two different kinds of vector-planes (the view you are looking at). We can use PCA like we did in the last section, but we can also use a different method whichi is specialized for the differences of the vectors below (here called something with SVD difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualizer = word_embedding_viz.WordEmbeddingVisualizer(fasttext_model=fasttext_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**  \n",
    "- *What method is best for plotting the differences of vectors?*  \n",
    "    Answer\n",
    "- *What method is best for plotting points alone?*  \n",
    "    Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document embeddings\n",
    "We now have an idea that word embeddings have some important information about words.  \n",
    "We will try to use the embeddings of the words for analysing documents.  \n",
    "\n",
    "Below are two tabs. The first tab allows you to search for words on Wikipedia and fetch the word-embeddings of the text. The second tab lets you write text-documents yourself.  \n",
    "\n",
    "The texts are used to compute vectors representing the documents, which can then be plotted in 3D.  \n",
    "Press \"Do Document Embeddings\" for showing the plot and use the dropdown menu for selecting what method used to create the document vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "doc_view = fasttext_document_visualisation.DocumentEmbeddingVisualiser(fasttext_model=fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
