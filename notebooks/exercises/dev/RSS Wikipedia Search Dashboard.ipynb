{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS Wikipedia Search Dashboard\n",
    "\n",
    "1. Initialize Danish Wikipedia\n",
    "2. Initialize RsspediaInit class\n",
    "3. Initialize the RSSWikiDashboard class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height: 10000px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height: 10000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text.document_retrieval.wikipedia import Wikipedia\n",
    "from notebooks.exercises.src.text.news_wiki_search_init import RsspediaInit\n",
    "from notebooks.exercises.src.text.news_wiki_dashboard import RSSWikiDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Danish Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parsed documents.\n",
      "Loading preprocessed documents.\n",
      "Wikipedia loaded.\n"
     ]
    }
   ],
   "source": [
    "wikipedia = Wikipedia(\n",
    "    language=\"Danish\",\n",
    "    cache_directory_url=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize RsspediaInit class\n",
    "\n",
    "In this initialization, the data that is needed to perform search is loaded.\n",
    "1. Okapi BM-25: uses precomputed wikipedia tf and idf vectors. No more preprocessing is done.\n",
    "2. Explicit Semantic Analysis: here we load the stored tf-idf vectors or compute them and store on disk.\n",
    "3. FTN-a and FTN-b: here we load the stored Fasttext vectors for wikipedia titles and abstracts or compute them and store on disk. As a preprocessing, non-alphanumeric characters are removed, and zero-length abstracts are removed as well. Wikipedia documents and titles are adjusted accordingly.\n",
    "<br><br>\n",
    "For both (2) and (3) we remove the following stop-words: <br>\n",
    "<code>stop_words = [\"den\", \"det\", \"denne\", \"dette\", \"en\", \"et\", \"om\", \"for\", \"til\", \"at\", \"af\", \"på\", \"som\", \"og\", \"er\", \"i\"]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading vectorized TF-IDF documents.\n",
      "Vectorized TF-IDF documents loaded.\n",
      "\n",
      "\n",
      "Initializing and loading Fasttext binaries.\n",
      "Fasttext initialized and loaded.\n",
      "\n",
      "\n",
      "Loading vectorized Fasttext documents.\n",
      "Vectorized Fasttext documents loaded.\n"
     ]
    }
   ],
   "source": [
    "rss_search_init = RsspediaInit(wikipedia = wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize and start the RSSWikiDashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Types of search and their descriptions:\n",
    "\n",
    "#### 3.1.1 Okapi BM-25\n",
    "\n",
    "In information retrieval, Okapi BM25 (BM stands for Best Matching) is a ranking function used by search engines to rank matching documents according to their relevance to a given search query. It is based on the probabilistic retrieval framework developed in the 1970s and 1980s by Stephen E. Robertson, Karen Spärck Jones, and others.\n",
    "\n",
    "The name of the actual ranking function is BM25. To set the right context, however, it is usually referred to as \"Okapi BM25\", since the Okapi information retrieval system, implemented at London's City University in the 1980s and 1990s, was the first system to implement this function.\n",
    "\n",
    "BM25 and its newer variants, e.g. BM25F (a version of BM25 that can take document structure and anchor text into account), represent state-of-the-art TF-IDF-like retrieval functions used in document retrieval.\n",
    "\n",
    "Given a query $Q$, containing keywords $ q_1,...,q_n$, the BM25 score of a document $D$ is:\n",
    "\n",
    "$$\n",
    "score(D,Q)=\\sum_{i=1}^n IDF(q_i) * \\frac{f(q_i,D)*(k_1+1)} {f(q_i,D)+k_1*(1-b+b*\\frac{|D|}{(avgdl)}},\n",
    "$$\n",
    "\n",
    "where $f(q_i,D)$ is $q_{i}$'s term frequency in the document $D$, $|D|$ is the length of the document $D$ in words, and $avgdl$ is the average document length in the text collection from which documents are drawn. $k_1$ and $b$ are free parameters, usually chosen, in absence of an advanced optimization, as $k_1\\in [1.2,2.0]$ and $b=0.75$. $IDF(q_i)$ is the IDF (inverse document frequency) weight of the query term $q_i$. \n",
    "\n",
    "It is usually computed as:\n",
    "\n",
    "$$\n",
    "IDF(q_i)=log((N-n(q_i)+0.5)/(n(q_i)+0.5),\n",
    "$$\n",
    "\n",
    "where $N$ is the total number of documents in the collection, and $n(q_i)$ is the number of documents containing $q_i$.\n",
    "\n",
    "#### 3.1.2 Explicit Semantic Analysis\n",
    "\n",
    "#### 3.1.3 FTN-a\n",
    "\n",
    "#### 3.1.4 FTN-b\n",
    "\n",
    "### 3.2 Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac386d101208477da2537b693de06f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Vælg nyhedskilde:', layout=Layout(width='400px'), options={'Politiken.dk'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rsswdb = RSSWikiDashboard(wikipedia, rss_search_init)\n",
    "rsswdb.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rsswdb.rsspedia_search.cdist_func([rss_search_init.sumVectorRepresentation(\"6\")],\n",
    "    [rss_search_init.sumVectorRepresentation(\"Guide Anmelderne anbefaler 6 gode spisesteder med pasta på menuen\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
