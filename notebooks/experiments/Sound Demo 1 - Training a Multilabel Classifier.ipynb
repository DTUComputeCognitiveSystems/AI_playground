{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound Demo 1\n",
    "This demo illustrates how to train a binary and a multilabel sound classifier using your microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run global setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run local setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.experiments.src.sound_demos.live_predictions import LivePredictions, run_livepred\n",
    "from notebooks.experiments.src.sound_demos.multilabel_classifier import Recorder, SoundClassifier\n",
    "from src.audio.mini_recorder import miniRecorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classifier\n",
    "A lot of existing models for training sound recognition...  \n",
    "Use a pretrained model to construct a binary sound classifier...  \n",
    "First we create or own dataset as basis for training. The below cell will start a recording process where you first record $n$ examples of the first class, followed by $n$ examples of the second class. Whenever a recording is finished the next one starts immediately after.  \n",
    "Things to keep in mind\n",
    "- You can decide to just make the sound of class 0 throughout the recording time for class 0, or you can try to match exactly one example of this sound for each recording. Whatever you choose, make sure to do the same for the second class. What do you think will happen if there is a lot of silence in class 0 recordings, but not in class 1 recordings?\n",
    "- How many examples do we need in each class in order to get a good classifier?\n",
    "- Will the length of the recorded examples affect performance?\n",
    "- How will background noise affect performance?\n",
    "- What happens (should happen) at test-time if sounds from both classes are present in a recording?\n",
    "\n",
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = Recorder(n_classes=2, n_files = 12, prefix='binary', wav_dir='/Users/nbip/proj/dtu/dtu-bach/dev/DataScienceVM/Audio/nbip_sounds3')\n",
    "recorder.record(seconds=2)\n",
    "data = recorder.create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you already recorded a dataset just use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = Recorder(n_classes=2, n_files = 12, prefix='binary', wav_dir='/Users/nbip/proj/dtu/dtu-bach/dev/DataScienceVM/Audio/nbip_sounds3')\n",
    "data = recorder.create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_classifier = SoundClassifier(mix=False)\n",
    "binary_classifier.train(data=data)\n",
    "binary_classifier.plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model\n",
    "Now we have a model that is trained to discriminate between two sounds. Try to make a recording of sound from one of the classes (or something completely different) and see what it is classified as by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = miniRecorder(seconds=1.5)\n",
    "_ = rec.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier.predict(sound_clip=rec.sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.playback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Predictions\n",
    "Let us use the live spectrogram to visualize the sound input to the computer microphone continuously and get running predictions from the model.\n",
    "What happens?\n",
    "- Does your binary classifier work?\n",
    "- Does the model predict one of the classes even when there is silence / background noise? Why? Do you have any ideas how to mitigate this?\n",
    "- What happens if you produce sound from both classes at the same time? What should ideally happen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_livepred(predictor=binary_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between class examples\n",
    "In order to help the model when sounds from both classes are present we can do some data augmentation:\n",
    "- Augment the training data by adding two sounds from different classes at a random ratio so that $\\text{mixed_sample} = rx_1 + (1-r)x_2$\n",
    "- The onehot encoding of the new label is $[r, (1-r)]$\n",
    "\n",
    "You can do this by changing mix=False to mix=True in the above specification of the SoundClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel classifier\n",
    "We can of course have an arbitrary number of sounds from different classes present in one recording. We now train a multilabel classifier to identify which classes are present. Again, you create the dataset yourself, so maybe in the interest of time go for 3 or 4 classes and not 50.\n",
    "\n",
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = Recorder(n_classes=4, n_files = 12, prefix='multi', wav_dir='/Users/nbip/proj/dtu/dtu-bach/dev/DataScienceVM/Audio/nbip_sounds3')\n",
    "recorder.record(seconds=2)\n",
    "data = recorder.create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you already have recorded a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = Recorder(n_classes=4, n_files = 12, prefix='multi', wav_dir='/Users/nbip/proj/dtu/dtu-bach/dev/DataScienceVM/Audio/nbip_sounds3')\n",
    "data = recorder.create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the multilabel classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_classifier = SoundClassifier(mix=False)\n",
    "multi_classifier.train(data=data)\n",
    "multi_classifier.plot_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_livepred(predictor=multi_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aib)",
   "language": "python",
   "name": "aib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
